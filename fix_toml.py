# # # # # # # # import os
# # # # # # # # from pathlib import Path
# # # # # # # #
# # # # # # # # # --- 1. DOSYA ƒ∞√áERƒ∞KLERƒ∞ (Doƒüru Baƒüƒ±mlƒ±lƒ±k Aƒüacƒ± ile) ---
# # # # # # # #
# # # # # # # # ROOT_TOML = """[tool.poetry]
# # # # # # # # name = "multi-ai-workspace"
# # # # # # # # version = "5.1.0"
# # # # # # # # description = "Multi-AI Enterprise Monorepo Root"
# # # # # # # # authors = ["Feridun <email@address.com>"]
# # # # # # # # package-mode = false
# # # # # # # #
# # # # # # # # [tool.poetry.dependencies]
# # # # # # # # python = "^3.10"
# # # # # # # #
# # # # # # # # # Local Libraries
# # # # # # # # multi-ai-core = {path = "./libs/core", develop = true}
# # # # # # # # multi-ai-utils = {path = "./libs/utils", develop = true}
# # # # # # # # multi-ai-llm = {path = "./libs/llm", develop = true}
# # # # # # # # multi-ai-rag = {path = "./libs/rag", develop = true}
# # # # # # # # multi-ai-agents = {path = "./libs/agents", develop = true}
# # # # # # # # multi-ai-orchestrator = {path = "./libs/orchestrator", develop = true}
# # # # # # # #
# # # # # # # # # External Dependencies
# # # # # # # # streamlit = "^1.32.0"
# # # # # # # # plotly = "^5.19.0"
# # # # # # # # fastapi = "^0.109.0"
# # # # # # # # uvicorn = "^0.27.0"
# # # # # # # # temporalio = "^1.4.0"
# # # # # # # # matplotlib = "^3.8.0"
# # # # # # # # Pillow = "^10.0.0"
# # # # # # # # watchdog = "^4.0.0"
# # # # # # # # scipy = "^1.11.0"
# # # # # # # # requests = "^2.31.0"
# # # # # # # # httpx = "^0.27.0"
# # # # # # # #
# # # # # # # # [build-system]
# # # # # # # # requires = ["poetry-core"]
# # # # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # # # """
# # # # # # # #
# # # # # # # # CORE_TOML = """[tool.poetry]
# # # # # # # # name = "multi-ai-core"
# # # # # # # # version = "0.1.0"
# # # # # # # # description = "Core System Config"
# # # # # # # # authors = ["MultiAI Team"]
# # # # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # # # #
# # # # # # # # [tool.poetry.dependencies]
# # # # # # # # python = "^3.10"
# # # # # # # # pydantic = "^2.6.0"
# # # # # # # # pydantic-settings = "^2.2.0"
# # # # # # # #
# # # # # # # # [build-system]
# # # # # # # # requires = ["poetry-core"]
# # # # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # # # """
# # # # # # # #
# # # # # # # # UTILS_TOML = """[tool.poetry]
# # # # # # # # name = "multi-ai-utils"
# # # # # # # # version = "0.1.0"
# # # # # # # # description = "Shared Utilities"
# # # # # # # # authors = ["MultiAI Team"]
# # # # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # # # #
# # # # # # # # [tool.poetry.dependencies]
# # # # # # # # python = "^3.10"
# # # # # # # # httpx = "^0.27.0"
# # # # # # # # requests = "^2.31.0"
# # # # # # # #
# # # # # # # # [build-system]
# # # # # # # # requires = ["poetry-core"]
# # # # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # # # """
# # # # # # # #
# # # # # # # # LLM_TOML = """[tool.poetry]
# # # # # # # # name = "multi-ai-llm"
# # # # # # # # version = "0.1.0"
# # # # # # # # description = "LLM Client"
# # # # # # # # authors = ["MultiAI Team"]
# # # # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # # # #
# # # # # # # # [tool.poetry.dependencies]
# # # # # # # # python = "^3.10"
# # # # # # # # multi-ai-core = {path = "../core", develop = true}
# # # # # # # # multi-ai-utils = {path = "../utils", develop = true}
# # # # # # # # openai = "^1.12.0"
# # # # # # # #
# # # # # # # # [build-system]
# # # # # # # # requires = ["poetry-core"]
# # # # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # # # """
# # # # # # # #
# # # # # # # # RAG_TOML = """[tool.poetry]
# # # # # # # # name = "multi-ai-rag"
# # # # # # # # version = "0.1.0"
# # # # # # # # description = "RAG System"
# # # # # # # # authors = ["MultiAI Team"]
# # # # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # # # #
# # # # # # # # [tool.poetry.dependencies]
# # # # # # # # python = "^3.10"
# # # # # # # # multi-ai-core = {path = "../core", develop = true}
# # # # # # # # multi-ai-utils = {path = "../utils", develop = true}
# # # # # # # # multi-ai-llm = {path = "../llm", develop = true}
# # # # # # # # qdrant-client = "^1.7.0"
# # # # # # # # sentence-transformers = "^2.2.2"
# # # # # # # #
# # # # # # # # [build-system]
# # # # # # # # requires = ["poetry-core"]
# # # # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # # # """
# # # # # # # #
# # # # # # # # AGENTS_TOML = """[tool.poetry]
# # # # # # # # name = "multi-ai-agents"
# # # # # # # # version = "0.1.0"
# # # # # # # # description = "AI Agents"
# # # # # # # # authors = ["MultiAI Team"]
# # # # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # # # #
# # # # # # # # [tool.poetry.dependencies]
# # # # # # # # python = "^3.10"
# # # # # # # # multi-ai-core = {path = "../core", develop = true}
# # # # # # # # multi-ai-utils = {path = "../utils", develop = true}
# # # # # # # # multi-ai-llm = {path = "../llm", develop = true}
# # # # # # # # multi-ai-rag = {path = "../rag", develop = true}
# # # # # # # #
# # # # # # # # [build-system]
# # # # # # # # requires = ["poetry-core"]
# # # # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # # # """
# # # # # # # #
# # # # # # # # ORCH_TOML = """[tool.poetry]
# # # # # # # # name = "multi-ai-orchestrator"
# # # # # # # # version = "0.1.0"
# # # # # # # # description = "Workflow Orchestrator"
# # # # # # # # authors = ["MultiAI Team"]
# # # # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # # # #
# # # # # # # # [tool.poetry.dependencies]
# # # # # # # # python = "^3.10"
# # # # # # # # temporalio = "^1.4.0"
# # # # # # # # multi-ai-core = {path = "../core", develop = true}
# # # # # # # # multi-ai-agents = {path = "../agents", develop = true}
# # # # # # # #
# # # # # # # # [build-system]
# # # # # # # # requires = ["poetry-core"]
# # # # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # # # """
# # # # # # # #
# # # # # # # # # --- 2. DOSYA YAZMA ƒ∞≈ûLEMƒ∞ ---
# # # # # # # #
# # # # # # # # FILES = {
# # # # # # # #     "pyproject.toml": ROOT_TOML,
# # # # # # # #     "libs/core/pyproject.toml": CORE_TOML,
# # # # # # # #     "libs/utils/pyproject.toml": UTILS_TOML,
# # # # # # # #     "libs/llm/pyproject.toml": LLM_TOML,
# # # # # # # #     "libs/rag/pyproject.toml": RAG_TOML,
# # # # # # # #     "libs/agents/pyproject.toml": AGENTS_TOML,
# # # # # # # #     "libs/orchestrator/pyproject.toml": ORCH_TOML,
# # # # # # # # }
# # # # # # # #
# # # # # # # #
# # # # # # # # def main():
# # # # # # # #     print("üöÄ TOML Dosyalarƒ± Onarƒ±lƒ±yor...")
# # # # # # # #
# # # # # # # #     for path_str, content in FILES.items():
# # # # # # # #         path = Path(path_str)
# # # # # # # #
# # # # # # # #         # Klas√∂r yoksa olu≈ütur
# # # # # # # #         if not path.parent.exists():
# # # # # # # #             path.parent.mkdir(parents=True, exist_ok=True)
# # # # # # # #             print(f"üìÅ Klas√∂r olu≈üturuldu: {path.parent}")
# # # # # # # #
# # # # # # # #         # Varsa sil (Bozuk encoding'den kurtulmak i√ßin)
# # # # # # # #         if path.exists():
# # # # # # # #             os.remove(path)
# # # # # # # #
# # # # # # # #         # Temiz UTF-8 olarak yaz
# # # # # # # #         with open(path, "w", encoding="utf-8", newline="\n") as f:
# # # # # # # #             f.write(content.strip() + "\n")
# # # # # # # #
# # # # # # # #         print(f"‚úÖ G√ºncellendi: {path}")
# # # # # # # #
# # # # # # # #     print("\n‚ú® ƒ∞≈ülem Tamamlandƒ±! ≈ûimdi 'poetry install' √ßalƒ±≈ütƒ±rabilirsiniz.")
# # # # # # # #
# # # # # # # #
# # # # # # # # if __name__ == "__main__":
# # # # # # # #     main()
# # # # # # #
# # # # # # # import os
# # # # # # #
# # # # # # # # Doƒüru TOML i√ßeriƒüi
# # # # # # # content = """[tool.poetry]
# # # # # # # name = "multi-ai-events"
# # # # # # # version = "0.1.0"
# # # # # # # description = "Event Schemas"
# # # # # # # authors = ["MultiAI Team"]
# # # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # # #
# # # # # # # [tool.poetry.dependencies]
# # # # # # # python = "^3.10"
# # # # # # # pydantic = "^2.6.0"
# # # # # # #
# # # # # # # [build-system]
# # # # # # # requires = ["poetry-core"]
# # # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # # """
# # # # # # #
# # # # # # # file_path = "libs/events/pyproject.toml"
# # # # # # #
# # # # # # # # Klas√∂r yoksa olu≈ütur
# # # # # # # os.makedirs(os.path.dirname(file_path), exist_ok=True)
# # # # # # #
# # # # # # # # Dosyayƒ± temiz UTF-8 olarak yaz
# # # # # # # with open(file_path, "w", encoding="utf-8", newline="\n") as f:
# # # # # # #     f.write(content.strip() + "\n")
# # # # # # #
# # # # # # # print(f"‚úÖ {file_path} ba≈üarƒ±yla onarƒ±ldƒ±!")
# # # # # #
# # # # # # import os
# # # # # # from pathlib import Path
# # # # # #
# # # # # # # --- 1. EKSƒ∞K MOD√úLLERƒ∞N TOML ƒ∞√áERƒ∞KLERƒ∞ ---
# # # # # #
# # # # # # SANDBOX_TOML = """[tool.poetry]
# # # # # # name = "multi-ai-sandbox"
# # # # # # version = "0.1.0"
# # # # # # description = "Secure Code Execution Environment"
# # # # # # authors = ["MultiAI Team"]
# # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # #
# # # # # # [tool.poetry.dependencies]
# # # # # # python = "^3.10"
# # # # # # multi-ai-core = {path = "../core", develop = true}
# # # # # # multi-ai-utils = {path = "../utils", develop = true}
# # # # # #
# # # # # # [build-system]
# # # # # # requires = ["poetry-core"]
# # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # """
# # # # # #
# # # # # # COMPLIANCE_TOML = """[tool.poetry]
# # # # # # name = "multi-ai-compliance"
# # # # # # version = "0.1.0"
# # # # # # description = "Security & Compliance Checks"
# # # # # # authors = ["MultiAI Team"]
# # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # #
# # # # # # [tool.poetry.dependencies]
# # # # # # python = "^3.10"
# # # # # # multi-ai-core = {path = "../core", develop = true}
# # # # # # multi-ai-llm = {path = "../llm", develop = true}
# # # # # #
# # # # # # [build-system]
# # # # # # requires = ["poetry-core"]
# # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # """
# # # # # #
# # # # # # GIT_TOML = """[tool.poetry]
# # # # # # name = "multi-ai-git"
# # # # # # version = "0.1.0"
# # # # # # description = "Git Operations Manager"
# # # # # # authors = ["MultiAI Team"]
# # # # # # packages = [{include = "multi_ai", from = "src"}]
# # # # # #
# # # # # # [tool.poetry.dependencies]
# # # # # # python = "^3.10"
# # # # # # multi-ai-core = {path = "../core", develop = true}
# # # # # # multi-ai-utils = {path = "../utils", develop = true}
# # # # # #
# # # # # # [build-system]
# # # # # # requires = ["poetry-core"]
# # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # """
# # # # # #
# # # # # # # --- 2. G√úNCELLENMƒ∞≈û ROOT TOML (HEPSƒ∞Nƒ∞ ƒ∞√áERƒ∞R) ---
# # # # # #
# # # # # # ROOT_TOML = """[tool.poetry]
# # # # # # name = "multi-ai-workspace"
# # # # # # version = "5.2.0"
# # # # # # description = "Multi-AI Enterprise Monorepo Root"
# # # # # # authors = ["Feridun <email@address.com>"]
# # # # # # package-mode = false
# # # # # #
# # # # # # [tool.poetry.dependencies]
# # # # # # python = "^3.10"
# # # # # #
# # # # # # # --- LOCAL LIBRARIES (TAM Lƒ∞STE) ---
# # # # # # multi-ai-core = {path = "./libs/core", develop = true}
# # # # # # multi-ai-utils = {path = "./libs/utils", develop = true}
# # # # # # multi-ai-llm = {path = "./libs/llm", develop = true}
# # # # # # multi-ai-rag = {path = "./libs/rag", develop = true}
# # # # # # multi-ai-agents = {path = "./libs/agents", develop = true}
# # # # # # multi-ai-orchestrator = {path = "./libs/orchestrator", develop = true}
# # # # # # multi-ai-events = {path = "./libs/events", develop = true}
# # # # # # # Yeni eklenenler:
# # # # # # multi-ai-sandbox = {path = "./libs/sandbox", develop = true}
# # # # # # multi-ai-compliance = {path = "./libs/compliance", develop = true}
# # # # # # multi-ai-git = {path = "./libs/git", develop = true}
# # # # # #
# # # # # # # --- EXTERNAL DEPENDENCIES ---
# # # # # # streamlit = "^1.32.0"
# # # # # # plotly = "^5.19.0"
# # # # # # fastapi = "^0.109.0"
# # # # # # uvicorn = "^0.27.0"
# # # # # # temporalio = "^1.4.0"
# # # # # # matplotlib = "^3.8.0"
# # # # # # Pillow = "^10.0.0"
# # # # # # watchdog = "^4.0.0"
# # # # # # scipy = "^1.11.0"
# # # # # # requests = "^2.31.0"
# # # # # # httpx = "^0.27.0"
# # # # # # faststream = "^0.4.0"
# # # # # # # Tƒ±rnak i√ßinde yazƒ±lmasƒ± gereken √∂zel paketler
# # # # # # "faststream[redis]" = "^0.4.0"
# # # # # # cryptography = "^42.0.0"
# # # # # # prometheus-client = "^0.20.0"
# # # # # #
# # # # # # [build-system]
# # # # # # requires = ["poetry-core"]
# # # # # # build-backend = "poetry.core.masonry.api"
# # # # # # """
# # # # # #
# # # # # # # --- 3. DOSYA YAZMA ---
# # # # # #
# # # # # # FILES = {
# # # # # #     "libs/sandbox/pyproject.toml": SANDBOX_TOML,
# # # # # #     "libs/compliance/pyproject.toml": COMPLIANCE_TOML,
# # # # # #     "libs/git/pyproject.toml": GIT_TOML,
# # # # # #     "pyproject.toml": ROOT_TOML
# # # # # # }
# # # # # #
# # # # # #
# # # # # # def main():
# # # # # #     print("üöÄ Eksik Mod√ºller Onarƒ±lƒ±yor...")
# # # # # #
# # # # # #     for path_str, content in FILES.items():
# # # # # #         path = Path(path_str)
# # # # # #
# # # # # #         # Klas√∂r yoksa olu≈ütur
# # # # # #         if not path.parent.exists():
# # # # # #             path.parent.mkdir(parents=True, exist_ok=True)
# # # # # #             print(f"üìÅ Klas√∂r olu≈üturuldu: {path.parent}")
# # # # # #
# # # # # #         # Dosyayƒ± yaz (UTF-8)
# # # # # #         with open(path, "w", encoding="utf-8", newline="\n") as f:
# # # # # #             f.write(content.strip() + "\n")
# # # # # #
# # # # # #         print(f"‚úÖ G√ºncellendi: {path}")
# # # # # #
# # # # # #     print("\n‚ú® ƒ∞≈ülem Tamamlandƒ±! L√ºtfen 'poetry install' √ßalƒ±≈ütƒ±rƒ±n.")
# # # # # #
# # # # # #
# # # # # # if __name__ == "__main__":
# # # # # #     main()
# # # # #
# # # # # import os
# # # # #
# # # # # # Doƒüru ve G√ºncel Baƒüƒ±mlƒ±lƒ±klar
# # # # # ROOT_TOML = """[tool.poetry]
# # # # # name = "multi-ai-workspace"
# # # # # version = "5.2.0"
# # # # # description = "Multi-AI Enterprise Monorepo Root"
# # # # # authors = ["Feridun <email@address.com>"]
# # # # # package-mode = false
# # # # #
# # # # # [tool.poetry.dependencies]
# # # # # python = "^3.10"
# # # # #
# # # # # # --- LOCAL LIBRARIES ---
# # # # # multi-ai-core = {path = "./libs/core", develop = true}
# # # # # multi-ai-utils = {path = "./libs/utils", develop = true}
# # # # # multi-ai-llm = {path = "./libs/llm", develop = true}
# # # # # multi-ai-rag = {path = "./libs/rag", develop = true}
# # # # # multi-ai-agents = {path = "./libs/agents", develop = true}
# # # # # multi-ai-orchestrator = {path = "./libs/orchestrator", develop = true}
# # # # # multi-ai-events = {path = "./libs/events", develop = true}
# # # # # multi-ai-sandbox = {path = "./libs/sandbox", develop = true}
# # # # # multi-ai-compliance = {path = "./libs/compliance", develop = true}
# # # # # multi-ai-git = {path = "./libs/git", develop = true}
# # # # #
# # # # # # --- EXTERNAL DEPENDENCIES ---
# # # # # streamlit = "^1.32.0"
# # # # # plotly = "^5.19.0"
# # # # # fastapi = "^0.109.0"
# # # # # uvicorn = "^0.27.0"
# # # # # temporalio = "^1.4.0"
# # # # # matplotlib = "^3.8.0"
# # # # # Pillow = "^10.0.0"
# # # # # watchdog = "^4.0.0"
# # # # # scipy = "^1.11.0"
# # # # # requests = "^2.31.0"
# # # # # httpx = "^0.27.0"
# # # # # cryptography = "^42.0.0"
# # # # # prometheus-client = "^0.20.0"
# # # # #
# # # # # # FastStream'i doƒüru ≈üekilde (Extras ile) ekliyoruz
# # # # # faststream = {extras = ["redis"], version = "^0.5.0"}
# # # # #
# # # # # [build-system]
# # # # # requires = ["poetry-core"]
# # # # # build-backend = "poetry.core.masonry.api"
# # # # # """
# # # # #
# # # # # file_path = "pyproject.toml"
# # # # #
# # # # # with open(file_path, "w", encoding="utf-8", newline="\n") as f:
# # # # #     f.write(ROOT_TOML.strip() + "\n")
# # # # #
# # # # # print(f"‚úÖ {file_path} baƒüƒ±mlƒ±lƒ±klarƒ± d√ºzeltildi!")
# # # #
# # # #
# # # # import os
# # # #
# # # # # --- 1. RESEARCHER AGENT (D√ºzeltilmi≈ü) ---
# # # # researcher_code = """import logging
# # # # from typing import Dict, Any, List
# # # # from .base import BaseAgent
# # # #
# # # # logger = logging.getLogger(__name__)
# # # #
# # # # class EnhancedResearcherAgent(BaseAgent):
# # # #     def __init__(self):
# # # #         super().__init__(role="Researcher", model="llama3.2:3b")
# # # #
# # # #     async def conduct_research(self, query: str) -> Dict[str, Any]:
# # # #         system_prompt = \"\"\"
# # # #         SEN KIDEMLƒ∞ Bƒ∞R TEKNƒ∞K ARA≈ûTIRMACISIN (SENIOR TECHNICAL RESEARCHER).
# # # #         G√∂revin: Verilen yazƒ±lƒ±m g√∂revini analiz etmek ve G√úNCEL, DOƒûRU teknik bilgiler saƒülamaktƒ±r.
# # # #
# # # #         KURALLAR:
# # # #         1. ASLA hayali k√ºt√ºphane veya mod√ºl uydurma. Sadece 'requests', 'pandas', 'numpy' gibi standart ve kanƒ±tlanmƒ±≈ü k√ºt√ºphaneleri √∂ner.
# # # #         2. Eƒüer emin deƒüilsen "Bilmiyorum" de, uydurma.
# # # #         3. Kodun √ßalƒ±≈üacaƒüƒ± ortamƒ± (Python 3.10+) g√∂z √∂n√ºnde bulundur.
# # # #         4. √áƒ±ktƒ±n sadece teknik ger√ßekleri i√ßermeli, laf kalabalƒ±ƒüƒ± yapma.
# # # #         \"\"\"
# # # #
# # # #         logger.info(f"üîé Ara≈ütƒ±rma yapƒ±lƒ±yor: {query}")
# # # #         result = await self._ask_llm(system_prompt, query)
# # # #
# # # #         return {
# # # #             "query": query,
# # # #             "findings": result,
# # # #             "source": "Local Knowledge & RAG"
# # # #         }
# # # # """
# # # #
# # # # # --- 2. ARCHITECT AGENT (D√ºzeltilmi≈ü) ---
# # # # architect_code = """import logging
# # # # import json
# # # # from typing import Dict, Any, List
# # # # from .base import BaseAgent
# # # #
# # # # logger = logging.getLogger(__name__)
# # # #
# # # # class EnhancedArchitectAgent(BaseAgent):
# # # #     def __init__(self):
# # # #         super().__init__(role="Architect", model="qwen2.5:7b")
# # # #
# # # #     async def create_manifest(self, research_data: dict, task: str) -> Dict[str, Any]:
# # # #         system_prompt = \"\"\"
# # # #         SEN BA≈û YAZILIM Mƒ∞MARISIN (CHIEF SOFTWARE ARCHITECT).
# # # #         G√∂revin: Verilen g√∂revi, hatasƒ±z √ßalƒ±≈üacak bir dosya yapƒ±sƒ±na ve uygulama planƒ±na d√∂n√º≈üt√ºrmektir.
# # # #
# # # #         √áIKTI FORMATI (KESƒ∞NLƒ∞KLE JSON):
# # # #         {
# # # #             "project_name": "proje_adi",
# # # #             "description": "Proje a√ßƒ±klamasƒ±",
# # # #             "dependencies": ["flask", "requests"],
# # # #             "artifacts": [
# # # #                 {
# # # #                     "path": "main.py",
# # # #                     "purpose": "Ana uygulama mantƒ±ƒüƒ±",
# # # #                     "instructions": "Detaylƒ± talimatlar..."
# # # #                 }
# # # #             ]
# # # #         }
# # # #
# # # #         KURALLAR:
# # # #         1. Sadece ge√ßerli JSON d√∂nd√ºr. Ba≈üka hi√ßbir metin yazma.
# # # #         2. Dosya yollarƒ± mantƒ±klƒ± ve d√ºzenli olsun.
# # # #         3. 'dependencies' listesine sadece ger√ßekten gerekenleri ekle.
# # # #         \"\"\"
# # # #
# # # #         context = f"Task: {task}\\nResearch: {json.dumps(research_data)}"
# # # #         logger.info(f"üèóÔ∏è Mimari plan hazƒ±rlanƒ±yor...")
# # # #
# # # #         raw_response = await self._ask_llm(system_prompt, context, json_mode=True)
# # # #
# # # #         try:
# # # #             return json.loads(raw_response)
# # # #         except json.JSONDecodeError:
# # # #             logger.error("Architect JSON √ºretemedi, Fallback kullanƒ±lƒ±yor.")
# # # #             return {
# # # #                 "project_name": "fallback_project",
# # # #                 "artifacts": [{"path": "main.py", "purpose": "Single file script", "instructions": task}]
# # # #             }
# # # # """
# # # #
# # # # # --- DOSYALARI YAZ ---
# # # # base_path = "libs/agents/src/multi_ai/agents"
# # # #
# # # # files = {
# # # #     f"{base_path}/researcher.py": researcher_code,
# # # #     f"{base_path}/architect.py": architect_code
# # # # }
# # # #
# # # # for path, content in files.items():
# # # #     os.makedirs(os.path.dirname(path), exist_ok=True)
# # # #     with open(path, "w", encoding="utf-8") as f:
# # # #         f.write(content.strip())
# # # #     print(f"‚úÖ D√ºzeltildi: {path}")
# # # #
# # # # print("‚ú® T√ºm eksik importlar eklendi.")
# # #
# # #
# # # import asyncio
# # # from temporalio.client import Client
# # #
# # #
# # # async def main():
# # #     print("üîå Temporal'a baƒülanƒ±lƒ±yor...")
# # #     client = await Client.connect("localhost:7233")
# # #
# # #     print("üîç √áalƒ±≈üan (Running) i≈ü akƒ±≈ülarƒ± taranƒ±yor...")
# # #
# # #     # Sadece 'Running' stat√ºs√ºndeki i≈üleri listele
# # #     count = 0
# # #     async for workflow in client.list_workflows('ExecutionStatus="Running"'):
# # #         w_id = workflow.id
# # #         r_id = workflow.run_id
# # #
# # #         try:
# # #             handle = client.get_workflow_handle(w_id, run_id=r_id)
# # #             await handle.terminate("Otomatik Temizlik üßπ")
# # #             print(f"‚úÖ SONLANDIRILDI: {w_id} (RunID: {r_id})")
# # #             count += 1
# # #         except Exception as e:
# # #             # Eƒüer tam o sƒ±rada bittiyse hatayƒ± yut ve devam et
# # #             print(f"‚ö†Ô∏è Zaten bitmi≈ü: {w_id}")
# # #
# # #     if count == 0:
# # #         print("üéâ Temiz! ≈ûu an √ßalƒ±≈üan hi√ß i≈ü akƒ±≈üƒ± yok.")
# # #     else:
# # #         print(f"üèÅ Toplam {count} adet zombi s√ºre√ß temizlendi.")
# # #
# # #
# # # if __name__ == "__main__":
# # #     asyncio.run(main())
# #
# #
# # import asyncio
# # import sys
# # import os
# #
# # # Proje yolunu ekle
# # sys.path.append(os.path.join(os.path.dirname(__file__), 'libs', 'utils', 'src'))
# #
# # from multi_ai.utils.robust_ollama_client import RobustOllamaClient
# #
# # async def test_ollama_client():
# #     print('üß™ RobustOllamaClient testi ba≈ülƒ±yor...')
# #     client = RobustOllamaClient()
# #     try:
# #         result = await client.generate(
# #             model='deepseek-coder:6.7b',
# #             prompt='print hello world in python',
# #             options={'temperature': 0.2}
# #         )
# #         print('‚úÖ BA≈ûARILI! Sonu√ß:')
# #         print(f'Response: {result.get(\"response\", \"No response\")}')
# #         return True
# #     except Exception as e:
# #         print(f'‚ùå HATA: {e}')
# #         import traceback
# #         traceback.print_exc()
# #         return False
# #
# # # Testi √ßalƒ±≈ütƒ±r
# # success = asyncio.run(test_ollama_client())
# # print(f'üéØ Test sonucu: {\"BA≈ûARILI\" if success else \"BA≈ûARISIZ\"}')
# # "
#
#
# import os
#
# # Worker ile %100 uyumlu, Pydantic V2 formatƒ±nda Settings dosyasƒ±
# SETTINGS_CONTENT = """from pydantic_settings import BaseSettings
# from pydantic import Field, ConfigDict
# from typing import Optional
# from pathlib import Path
#
# class KMSSettings(BaseSettings):
#     model_config = ConfigDict(extra='ignore')
#     provider: str = Field(default='local')
#     endpoint: Optional[str] = None
#     token: Optional[str] = None
#     mount_path: str = Field(default='secret')
#
# class DatabaseSettings(BaseSettings):
#     model_config = ConfigDict(extra='ignore')
#     url: str = 'postgresql://temporal:temporal@localhost:5432/temporal'
#     pool_size: int = 20
#     echo: bool = False
#
# class RedisSettings(BaseSettings):
#     model_config = ConfigDict(extra='ignore')
#     url: str = 'redis://localhost:6379'
#     stream_key: str = 'multi_ai:events'
#     consumer_group: str = 'multi_ai_workers'
#     consumer_name: str = 'worker_01'
#
# class TemporalSettings(BaseSettings):
#     model_config = ConfigDict(extra='ignore')
#     namespace: str = 'default'
#     address: str = 'localhost:7233'
#     task_queue: str = 'multi-ai-tasks'
#
# class ObservabilitySettings(BaseSettings):
#     model_config = ConfigDict(extra='ignore')
#     enabled: bool = True
#     endpoint: Optional[str] = None
#     service_name: str = 'multi-ai-platform'
#     service_version: str = '5.1.0'
#     log_level: str = 'INFO'
#
# # --- D√úZELTƒ∞LEN KISIM: OLLAMA AYARLARI ---
# class OllamaSettings(BaseSettings):
#     model_config = ConfigDict(extra='ignore')
#     # Windows i√ßin 127.0.0.1 zorunlu, /v1 kaldƒ±rƒ±ldƒ±
#     base_url: str = 'http://127.0.0.1:11434'
#     default_model: str = 'llama3.2:1b'
#     coder_model: str = 'deepseek-coder:6.7b'
#     temperature: float = 0.2
#
# class PlatformSettings(BaseSettings):
#     model_config = ConfigDict(env_prefix='MULTI_AI_', case_sensitive=False, extra='ignore')
#
#     environment: str = 'development'
#     debug: bool = True
#     log_format: str = 'json'
#
#     kms: KMSSettings = Field(default_factory=KMSSettings)
#     database: DatabaseSettings = Field(default_factory=DatabaseSettings)
#     redis: RedisSettings = Field(default_factory=RedisSettings)
#     temporal: TemporalSettings = Field(default_factory=TemporalSettings)
#     observability: ObservabilitySettings = Field(default_factory=ObservabilitySettings)
#
#     # ARTIK 'llm' YERƒ∞NE 'ollama' KULLANILIYOR
#     ollama: OllamaSettings = Field(default_factory=OllamaSettings)
#
#     github_app_id: Optional[str] = None
#     github_private_key: Optional[str] = None
#     github_webhook_secret: Optional[str] = "dummy_secret"
#
#     base_dir: Path = Path.cwd()
#     cache_dir: Path = Path.cwd() / '.cache'
#
# settings = PlatformSettings()
# """
#
# # Dosyayƒ± yaz
# file_path = "libs/core/src/multi_ai/core/settings.py"
# os.makedirs(os.path.dirname(file_path), exist_ok=True)
#
# with open(file_path, "w", encoding="utf-8") as f:
#     f.write(SETTINGS_CONTENT)
#
# print(f"‚úÖ {file_path} ba≈üarƒ±yla g√ºncellendi! (LLM -> Ollama d√∂n√º≈ü√ºm√º yapƒ±ldƒ±)")

import asyncio
from temporalio.client import Client

async def main():
    print("üîå Zombiler temizleniyor...")
    client = await Client.connect("localhost:7233")
    async for wf in client.list_workflows('ExecutionStatus="Running"'):
        await client.get_workflow_handle(wf.id, run_id=wf.run_id).terminate("Clean Restart")
        print(f"üíÄ √ñld√ºr√ºld√º: {wf.id}")

